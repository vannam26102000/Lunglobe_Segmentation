{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as dataset_torch\n",
    "from abc import ABC\n",
    "import os\n",
    "import SimpleITK as sitk\n",
    "import time\n",
    "import numpy as np\n",
    "from lungmask import utils\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "from lungmask import mask\n",
    "import SimpleITK as sitk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_extensions = [\n",
    "    '.nii.gz',\n",
    "]\n",
    "roi_extensions = [\n",
    "    '.roi.nii.gz',\n",
    "]\n",
    "\n",
    "\n",
    "def is_image_file(filename, mode='data'):\n",
    "    if mode == 'roi':\n",
    "        return any(filename.endswith(extension) for extension in roi_extensions)\n",
    "    elif mode == 'data':\n",
    "        if not 'roi' in filename and \\\n",
    "                any(filename.endswith(extension) for extension in data_extensions):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        raise ValueError('Undefined mode %s while reading data' % mode)\n",
    "\n",
    "\n",
    "def make_dataset(dir, max_dataset_size=float(\"inf\"), mode='data'):\n",
    "    images = []\n",
    "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
    "\n",
    "    for root, _, fnames in sorted(os.walk(dir)):\n",
    "        # return of os.walk: root dir, folders, files\n",
    "        for fname in fnames:\n",
    "            if is_image_file(fname, mode):\n",
    "                path = os.path.join(root, fname)\n",
    "                images.append(path)\n",
    "    return images[:min(max_dataset_size, len(images))]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 256, 256]             640\n",
      "              ReLU-2         [-1, 64, 256, 256]               0\n",
      "       BatchNorm2d-3         [-1, 64, 256, 256]             128\n",
      "            Conv2d-4         [-1, 64, 256, 256]          36,928\n",
      "              ReLU-5         [-1, 64, 256, 256]               0\n",
      "       BatchNorm2d-6         [-1, 64, 256, 256]             128\n",
      "     UNetConvBlock-7         [-1, 64, 256, 256]               0\n",
      "            Conv2d-8        [-1, 128, 128, 128]          73,856\n",
      "              ReLU-9        [-1, 128, 128, 128]               0\n",
      "      BatchNorm2d-10        [-1, 128, 128, 128]             256\n",
      "           Conv2d-11        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-12        [-1, 128, 128, 128]               0\n",
      "      BatchNorm2d-13        [-1, 128, 128, 128]             256\n",
      "    UNetConvBlock-14        [-1, 128, 128, 128]               0\n",
      "           Conv2d-15          [-1, 256, 64, 64]         295,168\n",
      "             ReLU-16          [-1, 256, 64, 64]               0\n",
      "      BatchNorm2d-17          [-1, 256, 64, 64]             512\n",
      "           Conv2d-18          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-19          [-1, 256, 64, 64]               0\n",
      "      BatchNorm2d-20          [-1, 256, 64, 64]             512\n",
      "    UNetConvBlock-21          [-1, 256, 64, 64]               0\n",
      "           Conv2d-22          [-1, 512, 32, 32]       1,180,160\n",
      "             ReLU-23          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-24          [-1, 512, 32, 32]           1,024\n",
      "           Conv2d-25          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-26          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-27          [-1, 512, 32, 32]           1,024\n",
      "    UNetConvBlock-28          [-1, 512, 32, 32]               0\n",
      "           Conv2d-29         [-1, 1024, 16, 16]       4,719,616\n",
      "             ReLU-30         [-1, 1024, 16, 16]               0\n",
      "      BatchNorm2d-31         [-1, 1024, 16, 16]           2,048\n",
      "           Conv2d-32         [-1, 1024, 16, 16]       9,438,208\n",
      "             ReLU-33         [-1, 1024, 16, 16]               0\n",
      "      BatchNorm2d-34         [-1, 1024, 16, 16]           2,048\n",
      "    UNetConvBlock-35         [-1, 1024, 16, 16]               0\n",
      "         Upsample-36         [-1, 1024, 32, 32]               0\n",
      "           Conv2d-37          [-1, 512, 32, 32]         524,800\n",
      "           Conv2d-38          [-1, 512, 32, 32]       4,719,104\n",
      "             ReLU-39          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-40          [-1, 512, 32, 32]           1,024\n",
      "           Conv2d-41          [-1, 512, 32, 32]       2,359,808\n",
      "             ReLU-42          [-1, 512, 32, 32]               0\n",
      "      BatchNorm2d-43          [-1, 512, 32, 32]           1,024\n",
      "    UNetConvBlock-44          [-1, 512, 32, 32]               0\n",
      "      UNetUpBlock-45          [-1, 512, 32, 32]               0\n",
      "         Upsample-46          [-1, 512, 64, 64]               0\n",
      "           Conv2d-47          [-1, 256, 64, 64]         131,328\n",
      "           Conv2d-48          [-1, 256, 64, 64]       1,179,904\n",
      "             ReLU-49          [-1, 256, 64, 64]               0\n",
      "      BatchNorm2d-50          [-1, 256, 64, 64]             512\n",
      "           Conv2d-51          [-1, 256, 64, 64]         590,080\n",
      "             ReLU-52          [-1, 256, 64, 64]               0\n",
      "      BatchNorm2d-53          [-1, 256, 64, 64]             512\n",
      "    UNetConvBlock-54          [-1, 256, 64, 64]               0\n",
      "      UNetUpBlock-55          [-1, 256, 64, 64]               0\n",
      "         Upsample-56        [-1, 256, 128, 128]               0\n",
      "           Conv2d-57        [-1, 128, 128, 128]          32,896\n",
      "           Conv2d-58        [-1, 128, 128, 128]         295,040\n",
      "             ReLU-59        [-1, 128, 128, 128]               0\n",
      "      BatchNorm2d-60        [-1, 128, 128, 128]             256\n",
      "           Conv2d-61        [-1, 128, 128, 128]         147,584\n",
      "             ReLU-62        [-1, 128, 128, 128]               0\n",
      "      BatchNorm2d-63        [-1, 128, 128, 128]             256\n",
      "    UNetConvBlock-64        [-1, 128, 128, 128]               0\n",
      "      UNetUpBlock-65        [-1, 128, 128, 128]               0\n",
      "         Upsample-66        [-1, 128, 256, 256]               0\n",
      "           Conv2d-67         [-1, 64, 256, 256]           8,256\n",
      "           Conv2d-68         [-1, 64, 256, 256]          73,792\n",
      "             ReLU-69         [-1, 64, 256, 256]               0\n",
      "      BatchNorm2d-70         [-1, 64, 256, 256]             128\n",
      "           Conv2d-71         [-1, 64, 256, 256]          36,928\n",
      "             ReLU-72         [-1, 64, 256, 256]               0\n",
      "      BatchNorm2d-73         [-1, 64, 256, 256]             128\n",
      "    UNetConvBlock-74         [-1, 64, 256, 256]               0\n",
      "      UNetUpBlock-75         [-1, 64, 256, 256]               0\n",
      "           Conv2d-76          [-1, 6, 256, 256]             390\n",
      "       LogSoftmax-77          [-1, 6, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 28,953,734\n",
      "Trainable params: 28,953,734\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.25\n",
      "Forward/backward pass size (MB): 1100.00\n",
      "Params size (MB): 110.45\n",
      "Estimated Total Size (MB): 1210.70\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "model = mask.get_model('unet','LTRCLobes')\n",
    "model.to('cuda')\n",
    "\n",
    "summary(model, (1,256,256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset(dataset_torch.Dataset, ABC):\n",
    "    def __init__(self, dir):\n",
    "        \"\"\"\n",
    "        dir: File directory.\n",
    "        \"\"\"\n",
    "        self.dir = dir\n",
    "        self.img_list = sorted(make_dataset(dir, mode='data'))\n",
    "        self.roi_list = sorted(make_dataset(dir, mode='roi'))\n",
    "        \n",
    "        self.A_size = len(self.img_list)  # get the size of dataset\n",
    "        self.B_size = len(self.roi_list)  # get the size of roi-set\n",
    "        \n",
    "        assert(self.A_size == self.B_size)\n",
    "        if self.A_size == 0:\n",
    "            raise(RuntimeError(\"Found 0 datafiles in: \" + dir))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return a data point and its metadata information.\n",
    "\n",
    "        Parameters:\n",
    "            index (int)      -- a random integer for data indexing\n",
    "\n",
    "        Returns a dictionary that contains A, B, A_paths and B_paths\n",
    "            A (tensor)       -- an image in the input domain\n",
    "            B (tensor)       -- its corresponding image in the target domain\n",
    "            A_paths (str)    -- image paths\n",
    "            B_paths (str)    -- image paths\n",
    "        \"\"\"\n",
    "        A_path = self.img_list[index] #% self.A_size]  # make sure index is within then range\n",
    "        B_path = self.roi_list[index] #% self.B_size]  # make sure index is within then range\n",
    "\n",
    "        # apply image transformation\n",
    "        A = sitk.ReadImage(A_path)  # data\n",
    "        B = sitk.ReadImage(B_path)  # roi\n",
    "\n",
    "        return {'A': A, 'B': B, 'A_paths': A_path, 'B_paths': B_path}\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the total number of images in the dataset.\n",
    "\n",
    "        As we have two datasets with potentially different number of images,\n",
    "        we take a maximum of\n",
    "        \"\"\"\n",
    "        return max(self.A_size, self.B_size)\n",
    "\n",
    "class LungLabelsDS_inf(dataset_torch.Dataset):\n",
    "    def __init__(self, ds, lb):\n",
    "        self.dataset = ds\n",
    "        self.label = lb\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.dataset[idx, None, :, :], self.label[idx, None, :, :]\n",
    "    \n",
    "def preprocess(img_data, roi_data):\n",
    "    img_raw = sitk.GetArrayFromImage(img_data)\n",
    "    roi_raw = sitk.GetArrayFromImage(roi_data)\n",
    "    directions = np.asarray(img_data.GetDirection())\n",
    "    if len(directions) == 9:\n",
    "        img_raw = np.flip(img_raw, np.where(directions[[0, 4, 8]][::-1] < 0)[0])\n",
    "        roi_raw = np.flip(roi_raw, np.where(directions[[0, 4, 8]][::-1] < 0)[0])\n",
    "\n",
    "    tvolslices, labelslices, xnew_box = utils.preprocess(img_raw, label=roi_raw, resolution=[256, 256])\n",
    "    \n",
    "#     print(np.shape(xnew_box))\n",
    "    \n",
    "    tvolslices = np.divide((tvolslices + 1024), 1624)\n",
    "    torch_ds_val = LungLabelsDS_inf(tvolslices, xnew_box)\n",
    "    \n",
    "    return torch.utils.data.DataLoader(torch_ds_val, batch_size=1, shuffle=True, num_workers=1, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as f\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DICELossMultiClass(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DICELossMultiClass, self).__init__()\n",
    "\n",
    "    def forward(self, output, mask_original):\n",
    "        num_classes = output.size(1)\n",
    "        \n",
    "        dice_eso = 0\n",
    "        for i in range(num_classes):\n",
    "            probs = torch.squeeze(output[:, i, :, :], 1)\n",
    "#             mask = torch.squeeze(mask[:, i, :, :], 1)\n",
    "            mask = torch.where(mask_original == i, torch.ones_like(Y).to(device), torch.zeros_like(Y).to(device))\n",
    "\n",
    "            num = probs * mask\n",
    "            num = torch.sum(num, 2)\n",
    "            num = torch.sum(num, 1)\n",
    "\n",
    "            # print( num )\n",
    "\n",
    "            den1 = probs * probs\n",
    "            # print(den1.size())\n",
    "            den1 = torch.sum(den1, 2)\n",
    "            den1 = torch.sum(den1, 1)\n",
    "\n",
    "            # print(den1.size())\n",
    "\n",
    "            den2 = mask * mask\n",
    "            # print(den2.size())\n",
    "            den2 = torch.sum(den2, 2)\n",
    "            den2 = torch.sum(den2, 1)\n",
    "\n",
    "            # print(den2.size())\n",
    "            eps = 0.0000001\n",
    "            dice = 2 * ((num + eps) / (den1 + den2 + eps))\n",
    "            # dice_eso = dice[:, 1:]\n",
    "            dice_eso += dice\n",
    "\n",
    "        loss = 1 - torch.sum(dice_eso) / dice_eso.size(0)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3360648/1597389609.py:55: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return self.dataset[idx, None, :, :].astype(np.float), self.label[idx, None, :, :].astype(np.float)\n",
      "/tmp/ipykernel_3360648/1597389609.py:55: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return self.dataset[idx, None, :, :].astype(np.float), self.label[idx, None, :, :].astype(np.float)\n",
      "/tmp/ipykernel_3360648/1597389609.py:55: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return self.dataset[idx, None, :, :].astype(np.float), self.label[idx, None, :, :].astype(np.float)\n",
      "/tmp/ipykernel_3360648/1597389609.py:55: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return self.dataset[idx, None, :, :].astype(np.float), self.label[idx, None, :, :].astype(np.float)\n",
      "/tmp/ipykernel_3360648/1597389609.py:55: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return self.dataset[idx, None, :, :].astype(np.float), self.label[idx, None, :, :].astype(np.float)\n",
      "/tmp/ipykernel_3360648/1597389609.py:55: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return self.dataset[idx, None, :, :].astype(np.float), self.label[idx, None, :, :].astype(np.float)\n",
      "/tmp/ipykernel_3360648/1597389609.py:55: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return self.dataset[idx, None, :, :].astype(np.float), self.label[idx, None, :, :].astype(np.float)\n",
      "/tmp/ipykernel_3360648/1597389609.py:55: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return self.dataset[idx, None, :, :].astype(np.float), self.label[idx, None, :, :].astype(np.float)\n",
      "/tmp/ipykernel_3360648/1597389609.py:55: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return self.dataset[idx, None, :, :].astype(np.float), self.label[idx, None, :, :].astype(np.float)\n",
      "/tmp/ipykernel_3360648/1597389609.py:55: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  return self.dataset[idx, None, :, :].astype(np.float), self.label[idx, None, :, :].astype(np.float)\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = mask.get_model('unet','LTRCLobes')\n",
    "model.to(device)\n",
    "\n",
    "criterion = torch.nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-1)\n",
    "\n",
    "dir = r'/home/avitech-pc4/Nam/data'\n",
    "dataset = BaseDataset(dir)\n",
    "\n",
    "total_iters = 0\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "for epoch in range(10):\n",
    "\n",
    "    for i, data in enumerate(dataset):\n",
    "\n",
    "        dataloader_val = preprocess(data['A'], data['B'])\n",
    "        \n",
    "        Loss = 0\n",
    "        epoch_loss = 0\n",
    "\n",
    "        for i, (X, Y) in enumerate(dataloader_val):\n",
    "            pass\n",
    "#             if (i % 2 == 0) and (i // 80 == 0):\n",
    "                \n",
    "#                 X = X.float().to(device)\n",
    "#                 label = torch.tensor(Y[:,0,:,:],dtype=torch.long).to(device)\n",
    "\n",
    "#                 prediction = model(X)\n",
    "                \n",
    "#                 Loss += criterion(prediction, label)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         Loss.backward()\n",
    "#         epoch_loss += Loss.item()\n",
    "#         print(epoch_loss)\n",
    "#         optimizer.step()\n",
    "\n",
    "\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 256, 256])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 256, 256])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1807, device='cuda:0', grad_fn=<NllLoss2DBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = nn.NLLLoss()\n",
    "\n",
    "label = torch.tensor(Y[:,0,:,:],dtype=torch.long)\n",
    "\n",
    "loss(prediction, label.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = torch.tensor(Y[:,0,:,:],dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 256])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thanhvip",
   "language": "python",
   "name": "thanhvip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
